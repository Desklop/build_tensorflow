# Build TensorFlow

Проект предназначен для сборки наиболее оптимизированной версии TensorFlow v1.13.1 и TensorFlow-GPU v1.13.1 специально под CPU и GPU на хост машине из исходников в docker контейнере.

**ПРИМЕЧАНИЕ:** базовый docker образ из официального репозитория [TensorFlow](https://hub.docker.com/r/tensorflow/tensorflow/) основан на ОС Ubuntu 18.04, соответственно любые собранные с помощью данного проекта версии TensorFlow можно будет устанавливать и запускать только в ОС Ubuntu 18.04.

---

# Docker образ

Для сборки TensorFlow v1.13.1 в качестве базового образа используется образ из официального репозитория [TensorFlow](https://hub.docker.com/r/tensorflow/tensorflow/) с меткой `tensorflow/tensorflow:devel-py3`.

Для сборки TensorFlow-GPU v1.13.1 в качестве базового образа используется образ с меткой `tensorflow/tensorflow:devel-gpu-py3`.

**ВНИМАНИЕ!** Для сборки TensorFlow-GPU v1.13.1 необходимо сначала подготовить хост машину! Подготовка заключается в установке официального драйвера версии 410.104 для вашей видеокарты NVIDIA и `nvidia-docker2`. Инструкцию и скрипты для установки можно найти в другом моём репозитории: [Docker_image_CUDA10.0_cuDNN7.5](https://github.com/Desklop/Docker_image_CUDA10.0_cuDNN7.5).

---

## Сборка TensorFlow для CPU

Для сборки образа с помощью Dockerfile необходимо перейти в терминале в папку с проектом и выполнить (`-t` — запуск терминала, `.` — директория, из которой вызывается docker build (точка — значит в текущей директории находятся все файлы для образа), `build_tensorflow_1.13.1:0.1` — метка образа и его версия):
```bash
sudo docker build -t build_tensorflow_1.13.1:0.1 .
```

После успешного выполнения данной операции вы можете вывести список имеющихся образов, выполнив:
```bash
sudo docker images
```
В полученном списке вы увидите наш образ — `build_tensorflow_1.13.1:0.1`.

Теперь вы можете запустить этот образ в контейнере (`--cpuset-cpus="0-5"` — использовать только ядра с 0 по 5, `-t` — запуск терминала, `-m 8GB` — использовать не более 8Гб оперативной памяти, `-i` — интерактивный режим, `--rm` — удалить контейнер после завершения его работы, `-v "$PWD:/mnt"` — папка, из которой запускается образ, будет доступна в контейнере по адресу `/mnt`, `-e HOST_PERMS="$(id -u):$(id -g)"` — перенос переменных окружения в контейнер (без этого bazel не захочет собирать TensorFlow)):
```
sudo docker run --cpuset-cpus="0-5" -m 8GB -ti --rm -v "$PWD:/mnt" -e HOST_PERMS="$(id -u):$(id -g)" build_tensorflow_1.13.1:0.1
```

При запуске контейнера сразу же начнётся сборка TensorFlow. На машине с CPU i7-8700 сборка на всех 12 ядрах занимает около 1.5 часов. При этом требуется около 15Гб оперативной памяти. После завершения сборки контейнер остановится и в папке, из которой он был запущен, появится файл `tensorflow_CPU_MODEL-1.13.1-cp36-cp36m-linux_x86_64.whl` (в случае CPU i7-8700: `tensorflow_i7_8700-1.13.1-cp36-cp36m-linux_x86_64.whl`), оптимизированный под CPU на хост машине.

Для установки TensorFlow из этого файла выполните:
```bash
sudo pip3 install tensorflow_i7_8700-1.13.1-cp36-cp36m-linux_x86_64.whl
```

Собранный docker-образ весит 2.72-2.89Гб.

---

## Сборка TensorFlow для GPU

**ВНИМАНИЕ!** Перед сборкой и запуском сначала нужно подготовить хост машину! Инструкцию и скрипты для подготовки можно найти [тут](https://github.com/Desklop/Docker_image_CUDA10.0_cuDNN7.5).

Перед сборкой необходимо немного изменить Dockerfile:
- раскомментировать 2-ю строку и закомментировать 3-ю
- раскомментировать предпоследнюю 39-ю строку и закомментировать последнюю 40-ю

Для сборки образа с помощью Dockerfile необходимо перейти в терминале в папку с проектом и выполнить:
```bash
sudo docker build -t build_tensorflow_gpu_1.13.1:0.1 .
```

После успешного выполнения данной операции вы можете вывести список имеющихся образов, выполнив:
```bash
sudo docker images
```
В полученном списке вы увидите наш образ — `build_tensorflow_gpu_1.13.1:0.1`.

Теперь вы можете запустить этот образ в контейнере (`--runtime=nvidia` — предоставить доступ к видеокарте):
```
sudo docker run --cpuset-cpus="0-5" -m 8GB --runtime=nvidia -ti --rm -v "$PWD:/mnt" -e HOST_PERMS="$(id -u):$(id -g)" build_tensorflow_1.13.1:0.1
```

При запуске контейнера сразу же начнётся сборка TensorFlow-GPU. На машине с CPU i7-8700 и GPU NVIDIA 1070 сборка на всех 12 ядрах занимает около 2 часов. При этом требуется около 15Гб оперативной памяти. После завершения сборки контейнер остановится и в папке, из которой он был запущен, появится файл `tensorflow_CPU_MODEL_GPU_MODEL-1.13.1-cp36-cp36m-linux_x86_64.whl` (в случае CPU i7-8700 и GPU NVIDIA 1070: `tensorflow_i7_8700_GeForceGTX1070-1.13.1-cp36-cp36m-linux_x86_64.whl`), оптимизированный под CPU и GPU на хост машине.

Для установки TensorFlow-GPU из этого файла выполните:
```bash
sudo pip3 install tensorflow_i7_8700_GeForceGTX1070-1.13.1-cp36-cp36m-linux_x86_64.whl
```

Собранный docker-образ весит 4.29-4.46Гб. На всякий случай, в исходных файлах проекта есть файл `command_for_docker.txt`, содержащий минимально необходимый набор команд для работы с docker.

---

## Дополнительные сведения

Для успешной сборки нужен GCC 4.8 или выше и Bazel 0.21.0. Для сборки с поддержкой GPU так же нужны CUDA 10.0 и cuDNN 7.5.

Инструкция по сборке вручную находится в `build_order.txt`. Получить дополнительную информацию, а так же другие инструкции по сборке (например, без использования docker), можно на [официальном сайте TensorFlow](https://www.tensorflow.org/install/source).

Изменить параметры сборки можно в скриптах `run_configure_cpu_1.13.1` и `run_configure_gpu_1.13.1` соответственно для CPU и GPU. Дополнительные параметры для сборщика bazel можно указать в скрипте `build` в строке 35.

Описание некоторых [флагов](https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions) (их можно добавить как в `run_configure_cpu_1.13.1` (строка 34) или `run_configure_gpu_1.13.1` (строка 46), так и в `build` (строка 35)):
- `-march=native` - использовать параметры текущего CPU (используется по умолчанию)
- `libverbs` - для удалённого прямого доступа к памяти Remote Direct Memory Access (RDMA) (нужно перед установкой выполнить `sudo apt-get install libibverbs-dev`)
- `ngraph` - поддержка компилятора Intel nGraph (не работает, а сборка nGraph из исходников не дала ускорения работы, только замедление где-то в 1.5 раза, см. комментарии в строках 3-5 в `build`)
- `gdr` - более крутая версия текущего протокола gRPC для распределённых вычислений на GPU (нужен когда размер тензора больше 100Мб)
- `monolithic` - сборка без возможности создания своих операций (подробнее [тут](https://stackoverflow.com/questions/53705582/what-is-meant-by-static-monolithic-build-when-building-tensorflow-from-source))
- `mkl` - поддержка библиотеки Intel Math Kernel Library (со сборкой для GPU приводит к уменьшению производительности, в сборке для CPU не приводит к изменению производительности (подробнее [тут](https://github.com/tensorflow/tensorflow/issues/23238)) и доступно только в Linux) (также можно использовать через `pip3 install intel-tensorflow`, подробнее [тут](https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide))

---

Если у вас возникнут вопросы или вы хотите сотрудничать, можете написать мне на почту: vladsklim@gmail.com или в [LinkedIn](https://www.linkedin.com/in/vladklim/).